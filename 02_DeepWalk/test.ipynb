{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import heapq\n",
    "from typing import Optional, Union\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.read_csv(\"BlogCatalog-dataset/nodes.csv\", names=[\"node\"])\n",
    "nodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = pd.read_csv(\"BlogCatalog-dataset/edges.csv\", names=[\"node1\", \"node2\"])\n",
    "edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = pd.read_csv(\"BlogCatalog-dataset/groups.csv\", names=[\"group\"])\n",
    "groups.head()\n",
    "group_edges = pd.read_csv(\n",
    "    \"BlogCatalog-dataset/group-edges.csv\", names=[\"node\", \"group\"]\n",
    ")\n",
    "group_edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_edges[\"node\"].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_train, nodes_test = train_test_split(nodes, test_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj_list(nodes: pd.DataFrame, edges: pd.DataFrame):\n",
    "    nodes = nodes[\"node\"].tolist()\n",
    "    adj_list = {node: [] for node in nodes}\n",
    "    for i in tqdm(range(len(edges)), desc=\"Formating adjacency list\"):\n",
    "        node1 = edges[\"node1\"].iloc[i]\n",
    "        node2 = edges[\"node2\"].iloc[i]\n",
    "        adj_list[node1].append(node2)\n",
    "        adj_list[node2].append(node1)\n",
    "    return adj_list\n",
    "\n",
    "\n",
    "adj_list = get_adj_list(nodes, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_node_random_walk(\n",
    "    adj_list: list,\n",
    "    begin_node: int,\n",
    "    t: int,\n",
    "):\n",
    "    \"\"\"一次随机游走\n",
    "\n",
    "    Args:\n",
    "        adj_list (list): 邻接表\n",
    "        begin_node (int): 最开始的节点\n",
    "        t (int): 游走的最长长度\n",
    "\n",
    "    Returns:\n",
    "        list: 一次随机游走得到的序列\n",
    "    \"\"\"\n",
    "    sequence = []\n",
    "    current_node = begin_node\n",
    "    sequence.append(current_node)\n",
    "    while len(sequence) < t:\n",
    "        adj_nodes = adj_list[current_node]\n",
    "        next_index = np.random.choice(np.arange(len(adj_nodes)))\n",
    "        current_node = adj_nodes[next_index]\n",
    "        sequence.append(current_node)\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_node_random_walk(\n",
    "    adj_list=adj_list,\n",
    "    begin_node=1,\n",
    "    t=40,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_height = int(np.ceil(np.log2(nodes.shape[0])))\n",
    "tree_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_height = 2\n",
    "target_idx = 2\n",
    "format(target_idx, f\"0{tree_height}b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tree_info(target_idx, tree_height):\n",
    "    binary_tree_code = format(target_idx, f\"0{tree_height}b\")\n",
    "    binary_tree_code = [int(c) for c in binary_tree_code]\n",
    "    path_nodes = [0]\n",
    "    c = 0\n",
    "    for char in binary_tree_code:\n",
    "        if char == 0:\n",
    "            c = c * 2 + 1\n",
    "        else:\n",
    "            c = c * 2 + 2\n",
    "        path_nodes.append(c)\n",
    "    path_nodes.pop(-1)\n",
    "    assert len(path_nodes) == len(binary_tree_code)\n",
    "    return binary_tree_code, path_nodes\n",
    "\n",
    "\n",
    "get_tree_info(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        nodes_num: int,\n",
    "        embedding_dim: int = 128,\n",
    "    ):\n",
    "        self.nodes_num = nodes_num\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = torch.randn([nodes_num, embedding_dim])\n",
    "        self.theta_p = torch.randn([2 * nodes_num, embedding_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(nodes_num=nodes.shape[0], embedding_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_gram(\n",
    "    model: Model, sequence: list, window_size: int, lr: float, tree_height, bias=1\n",
    "):\n",
    "    assert len(sequence) > (2 * window_size + 1)\n",
    "    loss_total = 0\n",
    "    for i in range(window_size, len(sequence)):\n",
    "        input_node = sequence[i]\n",
    "        context_nodes = (\n",
    "            sequence[i - window_size : i] + sequence[i + 1 : i + window_size + 1]\n",
    "        )\n",
    "        x = model.embedding[input_node - bias]  # [d]\n",
    "        for context_node in context_nodes:\n",
    "            bin_tree_code, path_nodes = get_tree_info(\n",
    "                context_node - bias, tree_height=tree_height\n",
    "            )\n",
    "            q = torch.sigmoid(x @ model.theta_p[path_nodes].T)  # [h]\n",
    "            loss = torch.nn.functional.binary_cross_entropy(\n",
    "                q, torch.tensor(bin_tree_code).float()\n",
    "            )\n",
    "            loss_total += loss\n",
    "            g = lr * (1 - torch.tensor(bin_tree_code).float() - q)  # [h]\n",
    "            model.theta_p[path_nodes] = model.theta_p[path_nodes] + g.unsqueeze(\n",
    "                dim=-1\n",
    "            ) * x.unsqueeze(0)\n",
    "            e = (g.unsqueeze(-1) * model.theta_p[path_nodes]).mean(dim=0)\n",
    "            model.embedding[input_node - bias] = model.embedding[input_node - bias] + e\n",
    "    print(loss_total.item() / len(sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    walks_num,\n",
    "    window_size,\n",
    "    t,\n",
    "    nodes: list,\n",
    "    adj_list,\n",
    "    lr: float,\n",
    "    bias: int = 1,\n",
    "    min_lr: float = 0.0001,\n",
    "):\n",
    "    node_list = nodes.copy()\n",
    "    tree_height = int(np.ceil(np.log2(len(nodes))))\n",
    "    for gamma in tqdm(range(walks_num), desc=\"Deep Walk\"):\n",
    "        random.shuffle(node_list)\n",
    "        for node in node_list:\n",
    "            sequence = one_node_random_walk(\n",
    "                adj_list=adj_list,\n",
    "                begin_node=node,\n",
    "                t=t,\n",
    "            )\n",
    "            skip_gram(\n",
    "                model=model,\n",
    "                sequence=sequence,\n",
    "                window_size=window_size,\n",
    "                lr=lr,\n",
    "                tree_height=tree_height,\n",
    "                bias=bias,\n",
    "            )\n",
    "        lr = lr - (lr - min_lr) * (gamma / walks_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(nodes_num=nodes.shape[0], embedding_dim=128)\n",
    "train(\n",
    "    model=model,\n",
    "    walks_num=30,\n",
    "    window_size=10,\n",
    "    t=40,\n",
    "    nodes=nodes[\"node\"].tolist(),\n",
    "    adj_list=adj_list,\n",
    "    lr=0.025,\n",
    "    bias=1,\n",
    "    min_lr=0.025,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练和测试分类模型\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import SkipGramHierarchicalSoftmaxModel\n",
    "\n",
    "model = SkipGramHierarchicalSoftmaxModel(nodes_num=nodes.shape[0], embedding_dim=128)\n",
    "model.load_state_dict(torch.load('model_save/model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_features = model.embedding.weight.detach().numpy()  # [n,d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_features.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros([nodes.shape[0], groups.shape[0]])\n",
    "for i in range(group_edges.shape[0]):\n",
    "    node = group_edges[\"node\"].iloc[i]\n",
    "    group = group_edges[\"group\"].iloc[i]\n",
    "    labels[node - 1][group - 1] = 1\n",
    "labels  # [n,g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = nodes_features\n",
    "y = labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7)\n",
    "\n",
    "base_classifier = LogisticRegression(solver=\"liblinear\")\n",
    "ovr_classifier = OneVsRestClassifier(base_classifier)\n",
    "ovr_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ovr_classifier.predict(X_test)\n",
    "f1_micro = f1_score(y_test, y_pred, average=\"micro\")\n",
    "f1_macro = f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "print(f\"F1-score (Micro): {f1_micro:.4f}\")\n",
    "print(f\"F1-score (Macro): {f1_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.arange(0, 12).reshape(2, 6)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = [\n",
    "    [[2, 1], [0, 1], [0, 1]],\n",
    "    [[2, 1], [1, 0], [0, 1]],\n",
    "]\n",
    "pos = torch.tensor(pos)\n",
    "pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = a[torch.arange(0, 2).unsqueeze(-1).unsqueeze(-1), pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.scatter(torch.zeros([2,3,6]),dim=2,index=torch.tensor([[1,2],[3,4]]).unsqueeze(2),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = torch.tensor([[1,2],[3,4]])\n",
    "t = torch.zeros([2,3,6])\n",
    "t.scatter_(2, index.unsqueeze(2), 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.view(-1,6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
