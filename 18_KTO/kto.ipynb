{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7abb44fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "from peft import (\n",
    "    PeftModel,\n",
    "    LoraConfig,\n",
    "    TaskType,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Literal\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f8cd118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b455a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"v_proj\",\n",
    "        \"k_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"down_proj\",\n",
    "        \"up_proj\",\n",
    "    ],\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3194b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 7,495,680 || all params: 1,844,324,352 || trainable%: 0.4064\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../model_save/base_model/qwen-1.5-1.8b/\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "model_policy = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "model_policy = prepare_model_for_kbit_training(model_policy)\n",
    "model_policy = get_peft_model(model_policy, peft_config)\n",
    "model_policy.print_trainable_parameters()\n",
    "model_ref = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8d4be77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c6d575b6114cc38fa59fa4c73b8efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"json\", data_files=\"./dataset/ultrafeedback/flan.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c36ba235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source', 'instruction', 'models', 'completions', 'correct_answers', 'incorrect_answers'],\n",
       "        num_rows: 20939\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57d73594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_pad_batch_tensors(\n",
    "    tensors_list,\n",
    "    padding_value=0,\n",
    "    padding_side: Literal[\"left\", \"right\"] = \"left\",\n",
    "):\n",
    "    \"\"\"手动实现批次张量的填充\"\"\"\n",
    "    # 获取最大序列长度\n",
    "    max_seq_len = max(t.shape[1] for t in tensors_list)\n",
    "\n",
    "    # 创建填充后的张量列表\n",
    "    padded_tensors = []\n",
    "    for tensor in tensors_list:\n",
    "        b, s = tensor.shape\n",
    "        # 创建填充张量\n",
    "        padding = torch.full(\n",
    "            (b, max_seq_len - s),\n",
    "            padding_value,\n",
    "            dtype=tensor.dtype,\n",
    "            device=tensor.device,\n",
    "        )\n",
    "        # 拼接原始张量和填充部分\n",
    "        if padding_side == \"left\":\n",
    "            padded = torch.cat([padding, tensor], dim=1)\n",
    "        elif padding_side == \"right\":\n",
    "            # 如果是右侧填充，则将填充部分放在后面\n",
    "            padded = torch.cat([tensor, padding], dim=1)\n",
    "        padded_tensors.append(padded)\n",
    "\n",
    "    return torch.cat(padded_tensors, dim=0)\n",
    "\n",
    "\n",
    "def sample_trans(sample):\n",
    "    question = sample[\"instruction\"]\n",
    "    completions = sample[\"completions\"]\n",
    "    scores_list = [[0, 0], [0, 1], [0, 2], [0, 3]]\n",
    "    responses = []\n",
    "    for i, annotation in enumerate(completions):\n",
    "        responses.append(annotation[\"response\"])\n",
    "        scores_list[i][0] = float(annotation[\"overall_score\"])\n",
    "    scores_list = sorted(scores_list, key=lambda x: x[0], reverse=True)\n",
    "    results = []\n",
    "    for i in range(1, 4):\n",
    "        results.append(\n",
    "            {\n",
    "                \"question\": question,\n",
    "                \"chosen\": responses[scores_list[0][1]],\n",
    "                \"rejected\": responses[scores_list[i][1]],\n",
    "            }\n",
    "        )\n",
    "    return results\n",
    "\n",
    "\n",
    "def process_function(sample, tokenizer):\n",
    "    query = sample[\"question\"]\n",
    "    chosen = sample[\"chosen\"]\n",
    "    rejected = sample[\"rejected\"]\n",
    "    chosen_inputs = tokenizer(\n",
    "        \"\\n\".join([query, chosen]),\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "    )\n",
    "    query_len = len(tokenizer(query)[\"input_ids\"])\n",
    "    chosen_answer_len = chosen_inputs[\"input_ids\"][0].shape[0] - query_len\n",
    "    chosen_answer_len = max(chosen_answer_len, 0)\n",
    "    rejected_inputs = tokenizer(\n",
    "        \"\\n\".join([query, rejected]),\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "    )\n",
    "    rejected_answer_len = rejected_inputs[\"input_ids\"][0].shape[0] - query_len\n",
    "    rejected_answer_len = max(rejected_answer_len, 0)\n",
    "    return {\n",
    "        \"chosen\": chosen_inputs,\n",
    "        \"rejected\": rejected_inputs,\n",
    "        \"chosen_answer_len\": chosen_answer_len,\n",
    "        \"rejected_answer_len\": rejected_answer_len,\n",
    "    }\n",
    "\n",
    "\n",
    "def collate_fn(batch, tokenizer):\n",
    "    chosen_input_ids = [torch.LongTensor(s[\"chosen\"][\"input_ids\"][0]) for s in batch]\n",
    "    chosen_attention_mask = [\n",
    "        torch.tensor(s[\"chosen\"][\"attention_mask\"][0]) for s in batch\n",
    "    ]\n",
    "    rejected_input_ids = [\n",
    "        torch.LongTensor(s[\"rejected\"][\"input_ids\"][0]) for s in batch\n",
    "    ]\n",
    "    rejected_attention_mask = [\n",
    "        torch.tensor(s[\"rejected\"][\"attention_mask\"][0]) for s in batch\n",
    "    ]\n",
    "    chosen_inputs = tokenizer.pad(\n",
    "        {\n",
    "            \"input_ids\": chosen_input_ids,\n",
    "            \"attention_mask\": chosen_attention_mask,\n",
    "        },\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        padding_side=\"left\",\n",
    "    )\n",
    "    rejected_inputs = tokenizer.pad(\n",
    "        {\n",
    "            \"input_ids\": rejected_input_ids,\n",
    "            \"attention_mask\": rejected_attention_mask,\n",
    "        },\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        padding_side=\"left\",\n",
    "    )\n",
    "    answer_mask_chosen = torch.zeros_like(chosen_inputs[\"input_ids\"])\n",
    "    answer_mask_rejected = torch.zeros_like(rejected_inputs[\"input_ids\"])\n",
    "    for i, s in enumerate(batch):\n",
    "        answer_mask_chosen[\n",
    "            i, answer_mask_chosen.shape[-1] - 1 - s[\"chosen_answer_len\"] :\n",
    "        ] = 1\n",
    "        answer_mask_rejected[\n",
    "            i, answer_mask_chosen.shape[1] - 1 - s[\"rejected_answer_len\"] :\n",
    "        ] = 1\n",
    "    return {\n",
    "        \"chosen_inputs\": chosen_inputs,\n",
    "        \"rejected_inputs\": rejected_inputs,\n",
    "        \"answer_mask_chosen\": answer_mask_chosen,\n",
    "        \"answer_mask_rejected\": answer_mask_rejected,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c8497b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 785, 6722,  315, 9625,  374]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"The capital of France is\"\n",
    "tokenizer(text, padding=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "166b7e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e8da9ebc4d4e2daa9032908d13bc8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/20939 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = dataset[\"train\"].filter(lambda x: len(x[\"instruction\"]) < 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8350f5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1579.17it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_dataset = []\n",
    "for sample in tqdm(train_dataset.select(range(1000))):\n",
    "    processed_dataset.extend(sample_trans(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37215144",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = Dataset.from_list(processed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02aa1080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f1c4152623942249ef7c260ae907bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_dataset = new_dataset.map(\n",
    "    lambda sample: process_function(sample, tokenizer),\n",
    "    batched=False,\n",
    "    remove_columns=[\"question\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec5e4787",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    new_dataset, batch_size=8, collate_fn=lambda x: collate_fn(x, tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5a3b4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_seq_log_prob(model, input_ids, attention_mask, answer_mask):\n",
    "    logits = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "    log_probs = F.log_softmax(logits, dim=-1)\n",
    "    log_probs = log_probs[:, :-1, :]\n",
    "    target_ids = input_ids[:, 1:]\n",
    "    target_log_probs = log_probs.gather(-1, target_ids.unsqueeze(-1)).squeeze(-1)\n",
    "    answer_mask = answer_mask[:, 1:]\n",
    "    target_log_probs = target_log_probs * answer_mask\n",
    "    return target_log_probs.sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "423b5808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_zero_estimate(policy_chosen, policy_rejected, ref_chosen, ref_rejected):\n",
    "    chosen_log_prob_diff = policy_chosen - ref_chosen  # [b]\n",
    "    ref_log_prob_diff = policy_rejected - ref_rejected  # [b]\n",
    "    log_prob_diff_all = torch.cat([chosen_log_prob_diff, ref_log_prob_diff], dim=0)\n",
    "    z_zero = log_prob_diff_all.mean()\n",
    "    return z_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "269b5e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kto_loss(\n",
    "    policy_chosen,\n",
    "    policy_rejected,\n",
    "    ref_chosen,\n",
    "    ref_rejected,\n",
    "    lambda_d,\n",
    "    lambda_u,\n",
    "    beta=0.1,\n",
    "):\n",
    "    z_zero = z_zero_estimate(policy_chosen, policy_rejected, ref_chosen, ref_rejected)\n",
    "    # 计算chosen 部分的损失\n",
    "    r_theta = policy_chosen - ref_chosen\n",
    "    loss_d = lambda_d * torch.sigmoid(beta * (r_theta - z_zero))\n",
    "    # 计算rejected 部分的损失\n",
    "    r_theta = policy_rejected - ref_rejected\n",
    "    loss_u = lambda_u * torch.sigmoid(beta * (z_zero - r_theta))\n",
    "    loss = (loss_d + loss_u).sum() / (len(loss_d) + len(loss_u))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bbdf029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_llm_kto(\n",
    "    policy_model,\n",
    "    ref_model,\n",
    "    train_data,\n",
    "    optimizer,\n",
    "    epochs=3,\n",
    "    lambda_d=1.0,\n",
    "    lambda_u=1.0,\n",
    "    beta=0.1,\n",
    "):\n",
    "    data_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "    lr_scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=len(dataloader) * epochs,\n",
    "    )\n",
    "    policy_model.train()\n",
    "    ref_model.eval()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        for batch in tqdm(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            chosen_ids = batch[\"chosen_inputs\"][\"input_ids\"].to(device)\n",
    "            rejected_ids = batch[\"rejected_inputs\"][\"input_ids\"].to(device)\n",
    "            attention_mask_chosen = batch[\"chosen_inputs\"][\"attention_mask\"].to(device)\n",
    "            attention_mask_rejected = batch[\"rejected_inputs\"][\"attention_mask\"].to(\n",
    "                device\n",
    "            )\n",
    "            answer_mask_chosen = batch[\"answer_mask_chosen\"].to(device)\n",
    "            answer_mask_rejected = batch[\"answer_mask_rejected\"].to(device)\n",
    "            policy_chosen_log_probs = calculate_seq_log_prob(\n",
    "                policy_model, chosen_ids, attention_mask_chosen, answer_mask_chosen\n",
    "            )\n",
    "            policy_rejected_log_probs = calculate_seq_log_prob(\n",
    "                policy_model,\n",
    "                rejected_ids,\n",
    "                attention_mask_rejected,\n",
    "                answer_mask_rejected,\n",
    "            )\n",
    "            with torch.no_grad():\n",
    "                ref_chosen_log_probs = calculate_seq_log_prob(\n",
    "                    ref_model, chosen_ids, attention_mask_chosen, answer_mask_chosen\n",
    "                )\n",
    "                ref_rejected_log_probs = calculate_seq_log_prob(\n",
    "                    ref_model,\n",
    "                    rejected_ids,\n",
    "                    attention_mask_rejected,\n",
    "                    answer_mask_rejected,\n",
    "                )\n",
    "            loss = kto_loss(\n",
    "                policy_chosen=policy_chosen_log_probs,\n",
    "                policy_rejected=policy_rejected_log_probs,\n",
    "                ref_chosen=ref_chosen_log_probs,\n",
    "                ref_rejected=ref_rejected_log_probs,\n",
    "                lambda_d=lambda_d,\n",
    "                lambda_u=lambda_u,\n",
    "                beta=beta,\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            del policy_chosen_log_probs, policy_rejected_log_probs\n",
    "            del ref_chosen_log_probs, ref_rejected_log_probs\n",
    "            torch.cuda.empty_cache()\n",
    "            lr_scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(data_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a14e1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/375 [00:00<?, ?it/s]You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "/root/miniconda3/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "  3%|▎         | 12/375 [00:25<12:47,  2.12s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m optimizer = torch.optim.AdamW(model_policy.parameters(), lr=\u001b[32m1e-5\u001b[39m)\n\u001b[32m      2\u001b[39m epochs = \u001b[32m3\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtrain_llm_kto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36mtrain_llm_kto\u001b[39m\u001b[34m(policy_model, ref_model, train_data, optimizer, epochs, lambda_d, lambda_u, beta)\u001b[39m\n\u001b[32m     44\u001b[39m     ref_rejected_log_probs = calculate_seq_log_prob(\n\u001b[32m     45\u001b[39m         ref_model,\n\u001b[32m     46\u001b[39m         rejected_ids,\n\u001b[32m     47\u001b[39m         attention_mask_rejected,\n\u001b[32m     48\u001b[39m         answer_mask_rejected,\n\u001b[32m     49\u001b[39m     )\n\u001b[32m     50\u001b[39m loss = kto_loss(\n\u001b[32m     51\u001b[39m     policy_chosen=policy_chosen_log_probs,\n\u001b[32m     52\u001b[39m     policy_rejected=policy_rejected_log_probs,\n\u001b[32m   (...)\u001b[39m\u001b[32m     57\u001b[39m     beta=beta,\n\u001b[32m     58\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m optimizer.step()\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m policy_chosen_log_probs, policy_rejected_log_probs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model_policy.parameters(), lr=1e-5)\n",
    "epochs = 3\n",
    "train_llm_kto(model_policy, model_ref, new_dataset, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64264ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
