{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import build_graph_from_edgelist\n",
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = build_graph_from_edgelist(\"graph/europe-airports.edgelist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20,\n",
       " 17,\n",
       " 19,\n",
       " 35,\n",
       " 101,\n",
       " 89,\n",
       " 138,\n",
       " 89,\n",
       " 112,\n",
       " 144,\n",
       " 75,\n",
       " 84,\n",
       " 65,\n",
       " 46,\n",
       " 42,\n",
       " 97,\n",
       " 98,\n",
       " 83,\n",
       " 131,\n",
       " 107,\n",
       " 202,\n",
       " 72,\n",
       " 116,\n",
       " 167,\n",
       " 64,\n",
       " 43,\n",
       " 136,\n",
       " 166,\n",
       " 12,\n",
       " 53,\n",
       " 75,\n",
       " 89,\n",
       " 40,\n",
       " 88,\n",
       " 81,\n",
       " 143,\n",
       " 156,\n",
       " 100,\n",
       " 149,\n",
       " 97,\n",
       " 117,\n",
       " 84,\n",
       " 19,\n",
       " 80,\n",
       " 33,\n",
       " 117,\n",
       " 43,\n",
       " 68,\n",
       " 1,\n",
       " 38,\n",
       " 84,\n",
       " 43,\n",
       " 48,\n",
       " 64,\n",
       " 128,\n",
       " 114,\n",
       " 76,\n",
       " 50,\n",
       " 66,\n",
       " 27,\n",
       " 82,\n",
       " 101,\n",
       " 37,\n",
       " 61,\n",
       " 51,\n",
       " 120,\n",
       " 31,\n",
       " 58,\n",
       " 35,\n",
       " 51,\n",
       " 88,\n",
       " 61,\n",
       " 80,\n",
       " 62,\n",
       " 51,\n",
       " 51,\n",
       " 21,\n",
       " 42,\n",
       " 71,\n",
       " 113,\n",
       " 86,\n",
       " 7,\n",
       " 101,\n",
       " 44,\n",
       " 42,\n",
       " 20,\n",
       " 36,\n",
       " 63,\n",
       " 43,\n",
       " 29,\n",
       " 50,\n",
       " 56,\n",
       " 23,\n",
       " 34,\n",
       " 111,\n",
       " 48,\n",
       " 42,\n",
       " 33,\n",
       " 61,\n",
       " 52,\n",
       " 15,\n",
       " 41,\n",
       " 40,\n",
       " 51,\n",
       " 53,\n",
       " 63,\n",
       " 85,\n",
       " 35,\n",
       " 12,\n",
       " 19,\n",
       " 45,\n",
       " 7,\n",
       " 17,\n",
       " 8,\n",
       " 23,\n",
       " 6,\n",
       " 44,\n",
       " 43,\n",
       " 39,\n",
       " 64,\n",
       " 27,\n",
       " 60,\n",
       " 45,\n",
       " 12,\n",
       " 8,\n",
       " 23,\n",
       " 40,\n",
       " 1,\n",
       " 2,\n",
       " 24,\n",
       " 38,\n",
       " 53,\n",
       " 49,\n",
       " 37,\n",
       " 47,\n",
       " 10,\n",
       " 41,\n",
       " 29,\n",
       " 73,\n",
       " 53,\n",
       " 31,\n",
       " 46,\n",
       " 72,\n",
       " 72,\n",
       " 6,\n",
       " 15,\n",
       " 56,\n",
       " 35,\n",
       " 38,\n",
       " 9,\n",
       " 6,\n",
       " 36,\n",
       " 30,\n",
       " 21,\n",
       " 70,\n",
       " 61,\n",
       " 26,\n",
       " 12,\n",
       " 27,\n",
       " 53,\n",
       " 20,\n",
       " 14,\n",
       " 39,\n",
       " 67,\n",
       " 6,\n",
       " 36,\n",
       " 25,\n",
       " 35,\n",
       " 40,\n",
       " 47,\n",
       " 33,\n",
       " 25,\n",
       " 52,\n",
       " 38,\n",
       " 40,\n",
       " 29,\n",
       " 10,\n",
       " 28,\n",
       " 32,\n",
       " 34,\n",
       " 6,\n",
       " 15,\n",
       " 38,\n",
       " 38,\n",
       " 18,\n",
       " 18,\n",
       " 17,\n",
       " 30,\n",
       " 8,\n",
       " 30,\n",
       " 38,\n",
       " 25,\n",
       " 28,\n",
       " 18,\n",
       " 32,\n",
       " 43,\n",
       " 18,\n",
       " 16,\n",
       " 22,\n",
       " 21,\n",
       " 8,\n",
       " 13,\n",
       " 23,\n",
       " 10,\n",
       " 32,\n",
       " 12,\n",
       " 27,\n",
       " 33,\n",
       " 53,\n",
       " 6,\n",
       " 11,\n",
       " 9,\n",
       " 6,\n",
       " 13,\n",
       " 14,\n",
       " 8,\n",
       " 17,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 28,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 10,\n",
       " 5,\n",
       " 8,\n",
       " 10,\n",
       " 7,\n",
       " 11,\n",
       " 11,\n",
       " 4,\n",
       " 7,\n",
       " 11,\n",
       " 6,\n",
       " 19,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 43,\n",
       " 39,\n",
       " 5,\n",
       " 16,\n",
       " 20,\n",
       " 21,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 11,\n",
       " 13,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 13,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 23,\n",
       " 11,\n",
       " 9,\n",
       " 12,\n",
       " 6,\n",
       " 12,\n",
       " 4,\n",
       " 12,\n",
       " 9,\n",
       " 14,\n",
       " 10,\n",
       " 11,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 27,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 13,\n",
       " 21,\n",
       " 8,\n",
       " 12,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 10,\n",
       " 13,\n",
       " 17,\n",
       " 19,\n",
       " 4,\n",
       " 4,\n",
       " 15,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 11,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 11,\n",
       " 12,\n",
       " 5,\n",
       " 10,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 14,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 16,\n",
       " 12,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = list(graph.nodes())\n",
    "degrees = [graph.degree(node) for node in nodes]\n",
    "degrees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"graph/labels-europe-airports.txt\",delimiter=\" \")\n",
    "y = np.array(labels['label'].tolist())\n",
    "nodes = labels[\"node\"].tolist()\n",
    "X = np.array([graph.degree(node) for node in nodes]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "classifier = LogisticRegression(\n",
    "        random_state=42,\n",
    "        penalty=\"l2\",\n",
    "        solver=\"liblinear\",\n",
    "        multi_class=\"ovr\",\n",
    "    )\n",
    "    # Perform 5-fold cross-validation\n",
    "mean_accuracies = []\n",
    "for i in range(5):\n",
    "    scores = cross_val_score(classifier, X, y, cv=5, scoring=\"accuracy\")\n",
    "    mean_accuracy = np.mean(scores)\n",
    "    mean_accuracies.append(mean_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49591772151898744"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_mean_accuracy = np.mean(mean_accuracies)\n",
    "overall_mean_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入嵌入\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"model_save/europe_word2vec.model\")\n",
    "nodes = sorted(labels[\"node\"].tolist())\n",
    "nodes_str = [str(node) for node in nodes]\n",
    "embeddings = [model.wv[node] for node in nodes_str]\n",
    "embeddings = np.stack(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C': 0.1, 'solver': 'liblinear', 'tol': 0.01}, 0.536139240506329)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = embeddings\n",
    "y = np.array(labels[\"label\"].tolist())\n",
    "# Split the data into training and testing sets\n",
    "# Standardize the embeddings\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Train a OneVsRest logistic regression classifier with L2 regularization\n",
    "# classifier = OneVsRestClassifier(\n",
    "#     LogisticRegression(\n",
    "#         random_state=42, penalty=\"l2\", tol=0.001, C=1, solver=\"liblinear\"\n",
    "#     )\n",
    "# )\n",
    "# classifier = OneVsRestClassifier(GradientBoostingClassifier())\n",
    "classifier = LogisticRegression(\n",
    "    random_state=42,\n",
    "    penalty=\"l2\",\n",
    "    tol=0.0001,\n",
    "    C=3,\n",
    "    solver=\"liblinear\",\n",
    "    multi_class=\"ovr\",\n",
    ")\n",
    "# Perform 5-fold cross-validation\n",
    "# mean_accuracies = []\n",
    "# for i in range(5):\n",
    "#     scores = cross_val_score(classifier, X, y, cv=5, scoring=\"accuracy\")\n",
    "#     mean_accuracy = np.mean(scores)\n",
    "#     mean_accuracies.append(mean_accuracy)\n",
    "\n",
    "# # Calculate and print the overall mean accuracy\n",
    "# overall_mean_accuracy = np.mean(mean_accuracies)\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'tol': [0.0001, 0.001, 0.01,0.00001],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(classifier, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "best_params, best_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
